{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37701237-192b-41ad-b658-abc8055d790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebe6836-b7d6-4f09-bbfe-c15c88d2771e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0350b0-e1e1-4baa-aefa-3ca9e7d9c1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_IN = './datasets/cc100_demo.txt'\n",
    "PATH_OUT = 'datasets/cc100_filtered'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9930da26-441a-46fc-912c-d5ffe15284d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(path_in, path_out):\n",
    "    raw_datasets = load_dataset('text', data_files=path)\n",
    "    \n",
    "    import re\n",
    "    import html as ihtml\n",
    "    from bs4 import BeautifulSoup\n",
    "\n",
    "    def clean_text(text):\n",
    "        text = BeautifulSoup(ihtml.unescape(text), \"lxml\").text\n",
    "        text = re.sub(r\"http[s]?://\\S+\", \"\", text)\n",
    "        text = re.sub(r\"\\s+\", \" \", text)\n",
    "        return text\n",
    "\n",
    "    filter_non_alfanum = lambda x: re.sub('[^0-9AaĄąBbCcĆćDdEeĘęFfGgHhIiJjKkLlŁłMmNnŃńOoÓóPpRrSsŚśTtUuWwYyZzŹźŻż\\,\\. ]+', '', x)\n",
    "    filter_ratio = lambda x: len(filter_non_alfanum(x)) / len(x)\n",
    "    \n",
    "    raw_datasets = raw_datasets.filter(lambda x: len(x['text']) > 20)\n",
    "    raw_datasets = raw_datasets.map(lambda x: {'text':  [clean_text(y) for y in x['text']]}, batched=True)\n",
    "    raw_datasets = raw_datasets.filter(lambda x: len(x['text']) > 20 and filter_ratio(x['text']) > 0.9)\n",
    "    raw_datasets.save_to_disk(path_out)\n",
    "    \n",
    "preprocess_dataset(PATH_IN, PATH_OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1874ed7-c0f1-41b9-9c72-a7f665f732fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.herbert.tokenization_herbert_fast import HerbertTokenizerFast\n",
    "tokenizer = HerbertTokenizerFast.from_pretrained(\"allegro/herbert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba6f73c-6197-41ef-bd5c-24d548f9ae15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from datasets import concatenate_datasets\n",
    "\n",
    "dedup_datasets = [load_dataset('json', data_files=path)['train'] for path in glob.glob('./datasets/data/*.json.gz')]\n",
    "dedup_dataset = concatenate_datasets(dedup_datasets)\n",
    "dedup_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c70da11-b75f-40ed-b09f-8513452d3d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_dataset(dedup_dataset, path_tokenized_out):    \n",
    "    def tokenize_function(example):\n",
    "        tokenized = tokenizer(example['text'], truncation=True)\n",
    "        return tokenized\n",
    "\n",
    "    tokenized_dataset = dedup_dataset.map(tokenize_function, batched=True)\n",
    "    tokenized_dataset = tokenized_dataset.remove_columns(['text', 'token_type_ids', 'hash', 'alpha_frac'])\n",
    "    tokenized_dataset = tokenized_dataset.with_format('torch')\n",
    "    tokenized_dataset = tokenized_dataset.train_test_split(test_size=0.01, seed=29)\n",
    "    tokenized_dataset.save_to_disk(path_tokenized_out)\n",
    "    \n",
    "tokenize_dataset(dedup_dataset, 'datasets/tokenized_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd779efd-1694-46a1-951a-cc75297447a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling, DataCollatorForWholeWordMask, DataCollatorWithPadding\n",
    "from datasets import load_from_disk\n",
    "from torch.utils.data import DataLoader\n",
    "def get_dataloaders(tokenizer, path_tokenized_dataset):\n",
    "    tokenized_datasets = load_from_disk(path_tokenized_dataset)\n",
    "    train_collator = DataCollatorForWholeWordMask(tokenizer=tokenizer)\n",
    "    test_collator = DataCollatorForWholeWordMask(tokenizer=tokenizer)\n",
    "    train_set = tokenized_datasets['train']\n",
    "    test_set = tokenized_datasets['test']\n",
    "    train = DataLoader(dataset=train_set, shuffle=True, batch_size=BATCH_SIZE, collate_fn=train_collator)\n",
    "    test = DataLoader(dataset=test_set, shuffle=False, batch_size=BATCH_SIZE, collate_fn=test_collator)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "\n",
    "train_loader, test_loader = get_dataloaders(tokenizer, 'datasets/tokenized_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89da5ce-49c5-4b69-8e05-1dfafd8bf228",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(test_loader))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5573cb-70bb-40ee-be9f-d99606dd9b9b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Whole Word Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa49f32-a2e0-45de-92e6-82519830a7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling, DataCollatorForWholeWordMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf297e3-d558-445f-a5f6-8d198430af5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = DataCollatorForWholeWordMask(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7031fced-575f-4e69-85a4-03ce078b105f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [\n",
    "    'Rejestracje żetonowe na przedmioty oferowane wspólnie dla wszystkich studentów UW odbywają się w serwisie UL dostępnym pod adresem',\n",
    "    'Nim przystąpisz do rejestracji, przeczytaj uważnie zasady opisane w zakładce aktualności. Pamiętaj, że w rejestracji mają uczestniczyć jedynie te osoby, które zapisują się na proseminarium lub seminarium danego rodzaju (matematyczne, informatyczne) po raz pierwszy. '\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff78a27e-49e7-4f5b-904d-969beea9ff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    tokenized = tokenizer(example, truncation=True)\n",
    "    word_ids = [tokenized.word_ids(i) for i in range(len(tokenized['input_ids']))]\n",
    "    tokenized['word_ids'] = word_ids \n",
    "    return tokenized\n",
    "tokenize_function(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b73ddc-c2d5-41d6-885b-2615c428594d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tokenizer(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88198095-7f7f-4372-a68d-c7ef5f02c6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99686ae0-ee1b-404d-9572-41e18fb35ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.word_ids(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8899ae-eb7a-4e75-8a23-5268640742e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = output['input_ids']\n",
    "collator(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f74b75-c920-4df0-8326-398f76b85539",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.word_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e230fe-dbb1-45a3-beab-9a64a1460549",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a155e024-0f7b-4ddc-8f71-a066130ed58c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8c51eb-7c9c-4fec-b32c-f8ddce1095f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1 = load_dataset('json', data_files='datasets/data/file-000000000001.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e88932-17c6-41ed-a30f-6cb953d23263",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2 = load_dataset('json', data_files='datasets/data/file-000000000002.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2539e784-da59-4ac5-81c0-c9c66552cc14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c458fd-ee10-4d8e-a08b-39cb05a31691",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [data['train'] for data in datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae2d996-ddad-4621-8f1e-7eb4bade08e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b27395b1-baac-4555-8daa-1e392f8b37c5",
   "metadata": {},
   "source": [
    "# HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8f5065d-089e-4b10-a209-d4ca1d9e5e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77c3a1a4-d778-48ca-99ca-1268ce10691a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm a transformer called BERT\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I&#039;m a transformer called BERT\"\n",
    "html.unescape(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d675ae1c-c85d-42c6-9557-fcdcf5445116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<div>\\n<h1>Title</h1>\\n<p>A long text........ </p>\\n<a href=\"\"> a link </a>\\n</div>'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"<div>\n",
    "<h1>Title</h1>\n",
    "<p>A long text........ </p>\n",
    "<a href=\"\"> a link </a>\n",
    "</div>\"\"\"\n",
    "html.unescape(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a72de8c1-d5b1-4e06-940c-f679bacae0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<div>\\n<h1>Title</h1>\\n<p>A long text........ </p>\\n<a href=\"\"> a link </a>\\n</div>'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html.unescape(html.escape(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db85c9fc-c2a2-4048-9cc2-b2a80766d4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa46efa5-9c21-4108-8e33-1e4ae42fc687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTitle\\nA long text........ \\n a link \\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BeautifulSoup(html.unescape(text), \"lxml\").text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18612546-b6fd-43f8-9190-6e78b220abb5",
   "metadata": {},
   "source": [
    "# Dataset Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e71035-f4d0-4eb8-99a6-501f379ade50",
   "metadata": {},
   "source": [
    "### Num of Chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce655816-4d7e-4363-acd8-b6939e030148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0a76f44-963c-446b-a410-7ad56f014cbd",
   "metadata": {},
   "source": [
    "### Num of Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b0bc98-9905-4726-a628-6b7bc5898e01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tldl",
   "language": "python",
   "name": "tldl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
